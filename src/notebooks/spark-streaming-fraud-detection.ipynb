{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Spark Streaming\n",
    "\n",
    "Ten notebook demonstruje zastosowanie Spark Streaming do detekcji oszustw bankowych.\n",
    "\n",
    "\n",
    "Zadanie: Bank chce automatycznie wykrywać podejrzane transakcje, potrzebuje rozwiązania analizującego napływające dane na bieżąco.\n",
    "\n",
    "\n",
    "Dane: https://www.kaggle.com/datasets/ealaxi/paysim1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "380d6c136592a511"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-26T04:33:51.496678Z",
     "start_time": "2025-04-26T04:33:51.474980Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<pyspark.sql.session.SparkSession at 0x121d9fd10>",
      "text/html": "\n            <div>\n                <p><b>SparkSession - in-memory</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://192.168.0.108:4040\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.5.0</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[*]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Fraud Detection</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Fraud Detection\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "project_dir = \"<PROJECT_DIR>\"\n",
    "data_dir = f\"{project_dir}/data\"\n",
    "outputs_dir = f\"{data_dir}/outputs\"\n",
    "input_tables = f\"{data_dir}/paysim/\"\n",
    "output_tables = f\"{outputs_dir}/paysim/\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-26T04:34:08.260965Z",
     "start_time": "2025-04-26T04:34:08.257940Z"
    }
   },
   "id": "a456b9c0cf0354c7",
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3ef74da0c43eeead"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(input_tables, header=True, inferSchema=True) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-26T04:34:15.975878Z",
     "start_time": "2025-04-26T04:34:14.113707Z"
    }
   },
   "id": "4b34822a47254226",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/26 06:34:37 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "25/04/26 06:34:37 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "25/04/26 06:34:37 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "25/04/26 06:34:40 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "25/04/26 06:34:40 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.parquet(f\"{output_tables}/paysim.parquet\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-26T04:34:40.668432Z",
     "start_time": "2025-04-26T04:34:37.384925Z"
    }
   },
   "id": "d2dc8d0ba8039dbe",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- step: integer (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- amount: double (nullable = true)\n",
      " |-- nameOrig: string (nullable = true)\n",
      " |-- oldbalanceOrg: double (nullable = true)\n",
      " |-- newbalanceOrig: double (nullable = true)\n",
      " |-- nameDest: string (nullable = true)\n",
      " |-- oldbalanceDest: double (nullable = true)\n",
      " |-- newbalanceDest: double (nullable = true)\n",
      " |-- isFraud: integer (nullable = true)\n",
      " |-- isFlaggedFraud: integer (nullable = true)\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-26T04:34:43.273341Z",
     "start_time": "2025-04-26T04:34:43.268708Z"
    }
   },
   "id": "8c7a829143ffeece",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['step',\n 'type',\n 'amount',\n 'nameOrig',\n 'oldbalanceOrg',\n 'newbalanceOrig',\n 'nameDest',\n 'oldbalanceDest',\n 'newbalanceDest',\n 'isFraud',\n 'isFlaggedFraud']"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-26T04:34:50.864171Z",
     "start_time": "2025-04-26T04:34:50.859891Z"
    }
   },
   "id": "a77fdd8111f06647",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+-------+-----------+-------------+--------------+-----------+--------------+--------------+-------+--------------+\n",
      "|step|    type| amount|   nameOrig|oldbalanceOrg|newbalanceOrig|   nameDest|oldbalanceDest|newbalanceDest|isFraud|isFlaggedFraud|\n",
      "+----+--------+-------+-----------+-------------+--------------+-----------+--------------+--------------+-------+--------------+\n",
      "|   1|TRANSFER|  181.0|C1305486145|        181.0|           0.0| C553264065|           0.0|           0.0|      1|             0|\n",
      "|   1|CASH_OUT|  181.0| C840083671|        181.0|           0.0|  C38997010|       21182.0|           0.0|      1|             0|\n",
      "|   1|TRANSFER| 2806.0|C1420196421|       2806.0|           0.0| C972765878|           0.0|           0.0|      1|             0|\n",
      "|   1|CASH_OUT| 2806.0|C2101527076|       2806.0|           0.0|C1007251739|       26202.0|           0.0|      1|             0|\n",
      "|   1|TRANSFER|20128.0| C137533655|      20128.0|           0.0|C1848415041|           0.0|           0.0|      1|             0|\n",
      "+----+--------+-------+-----------+-------------+--------------+-----------+--------------+--------------+-------+--------------+\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df.where(col(\"isFraud\") == 1).show(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-26T04:37:49.762250Z",
     "start_time": "2025-04-26T04:37:49.633699Z"
    }
   },
   "id": "6b499d30064f6c68",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 371:>                                                        (0 + 5) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+----------+-----------+-------------+--------------+-----------+--------------+--------------+-------+--------------+\n",
      "|step|    type|    amount|   nameOrig|oldbalanceOrg|newbalanceOrig|   nameDest|oldbalanceDest|newbalanceDest|isFraud|isFlaggedFraud|\n",
      "+----+--------+----------+-----------+-------------+--------------+-----------+--------------+--------------+-------+--------------+\n",
      "| 212|TRANSFER|4953893.08| C728984460|   4953893.08|    4953893.08| C639921569|           0.0|           0.0|      1|             1|\n",
      "| 250|TRANSFER|1343002.08|C1100582606|   1343002.08|    1343002.08|C1147517658|           0.0|           0.0|      1|             1|\n",
      "| 279|TRANSFER| 536624.41|C1035541766|    536624.41|     536624.41|C1100697970|           0.0|           0.0|      1|             1|\n",
      "| 387|TRANSFER|4892193.09| C908544136|   4892193.09|    4892193.09| C891140444|           0.0|           0.0|      1|             1|\n",
      "| 425|TRANSFER|     1.0E7| C689608084|1.958504037E7| 1.958504037E7|C1392803603|           0.0|           0.0|      1|             1|\n",
      "+----+--------+----------+-----------+-------------+--------------+-----------+--------------+--------------+-------+--------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df.where(col(\"isFlaggedFraud\") == 1).show(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-26T04:37:53.591850Z",
     "start_time": "2025-04-26T04:37:50.616208Z"
    }
   },
   "id": "806bd7535a3ec0e2",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/26 06:37:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/26 06:37:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/26 06:37:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/26 06:37:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/26 06:37:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/26 06:37:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/26 06:37:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/26 06:37:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/26 06:37:55 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/26 06:37:55 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/26 06:37:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/26 06:37:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/26 06:37:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/26 06:37:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/26 06:37:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/26 06:37:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/26 06:37:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/26 06:37:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/26 06:37:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/26 06:37:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "6353307"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# możemy policzyć name orig\n",
    "df.select(\"nameOrig\").distinct().count()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-26T04:37:57.839015Z",
     "start_time": "2025-04-26T04:37:53.598156Z"
    }
   },
   "id": "54603d944c7d7551",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "2722362"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(\"nameDest\").distinct().count()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-26T04:37:59.532373Z",
     "start_time": "2025-04-26T04:37:57.840377Z"
    }
   },
   "id": "b06893f493535037",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "6362620"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-26T04:37:59.999810Z",
     "start_time": "2025-04-26T04:37:59.533890Z"
    }
   },
   "id": "af02042514c1b955",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "9313"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Różnica nameDest i nameOrig\n",
    "6362620 - 6353307"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-26T04:38:00.003029Z",
     "start_time": "2025-04-26T04:38:00.000647Z"
    }
   },
   "id": "7075b00b3c6dcf0c",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+--------+-----------+-------------+--------------+-----------+--------------+--------------+\n",
      "|step|    type|  amount|   nameOrig|oldbalanceOrg|newbalanceOrig|   nameDest|oldbalanceDest|newbalanceDest|\n",
      "+----+--------+--------+-----------+-------------+--------------+-----------+--------------+--------------+\n",
      "|   1| PAYMENT| 9839.64|C1231006815|     170136.0|     160296.36|M1979787155|           0.0|           0.0|\n",
      "|   1| PAYMENT| 1864.28|C1666544295|      21249.0|      19384.72|M2044282225|           0.0|           0.0|\n",
      "|   1|TRANSFER|   181.0|C1305486145|        181.0|           0.0| C553264065|           0.0|           0.0|\n",
      "|   1|CASH_OUT|   181.0| C840083671|        181.0|           0.0|  C38997010|       21182.0|           0.0|\n",
      "|   1| PAYMENT|11668.14|C2048537720|      41554.0|      29885.86|M1230701703|           0.0|           0.0|\n",
      "+----+--------+--------+-----------+-------------+--------------+-----------+--------------+--------------+\n"
     ]
    }
   ],
   "source": [
    "# usuwamy - nie potrzebujemy\n",
    "df = df.drop(\"isFraud\", \"isFlaggedFraud\")\n",
    "df.show(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-26T04:38:02.684485Z",
     "start_time": "2025-04-26T04:38:02.647575Z"
    }
   },
   "id": "16aede47f3b96e8f",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 388:>                                                      (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+\n",
      "|    type|  count|\n",
      "+--------+-------+\n",
      "|TRANSFER| 532909|\n",
      "| CASH_IN|1399284|\n",
      "|CASH_OUT|2237500|\n",
      "| PAYMENT|2151495|\n",
      "|   DEBIT|  41432|\n",
      "+--------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"type\").count().show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-26T04:38:08.681282Z",
     "start_time": "2025-04-26T04:38:07.352085Z"
    }
   },
   "id": "42dfb779d51078a1",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9acce3b5253197ef"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Krok (step) odwzorowuje jednostkę czasu w rzeczywistym świecie.\n",
    "W tym przypadku 1 krok to 1 godzina.\n",
    "Możemy więc założyć, że w naszym przykładzie istnieje inna praca (job), która uruchamia się co godzinę i pobiera wszystkie transakcje z tego przedziału czasowego.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "70cd2323b55395a5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.groupBy(\"step\").count().show(3)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9f2ede66250967e"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 391:>                                                      (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|step|count|\n",
      "+----+-----+\n",
      "|  19|51352|\n",
      "|  18|49579|\n",
      "| 187|49083|\n",
      "| 235|47491|\n",
      "| 307|46968|\n",
      "| 163|46352|\n",
      "| 139|46054|\n",
      "| 403|45155|\n",
      "|  43|45060|\n",
      "| 355|44787|\n",
      "|  15|44609|\n",
      "| 186|43747|\n",
      "| 306|43615|\n",
      "|  17|43361|\n",
      "| 259|43328|\n",
      "|  16|42471|\n",
      "| 379|41759|\n",
      "|  14|41485|\n",
      "|  42|41304|\n",
      "| 354|40696|\n",
      "+----+-----+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"step\").count().orderBy(F.desc(\"count\")).show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-26T04:38:12.154050Z",
     "start_time": "2025-04-26T04:38:11.088600Z"
    }
   },
   "id": "326ee42c57a949cf",
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "source": [
    "Możemy więc zapisywać wyniki tej pracy, filtrując dane dla każdego kroku i zapisując je do osobnego pliku."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9eb2894d963d15eb"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "743"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(\"step\").distinct().count()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-26T04:38:16.387095Z",
     "start_time": "2025-04-26T04:38:15.582577Z"
    }
   },
   "id": "8df9eab3b5390c15",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "743"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps = df.select(\"step\").distinct().collect()\n",
    "len(steps)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-26T04:43:59.969256Z",
     "start_time": "2025-04-26T04:43:58.905716Z"
    }
   },
   "id": "3617dcbc904fa1cf",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "for step in steps[:]:\n",
    "    _df = df.where(df.step == step[0])\n",
    "    _df.coalesce(1).write.mode(\"append\").option(\"header\", \"true\").csv(f\"{output_tables}/paysim_by_steps\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-26T05:40:39.632564Z",
     "start_time": "2025-04-26T04:45:06.492885Z"
    }
   },
   "id": "260fab6b82bb58d1",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "part = spark.read.csv(f\"{output_tables}/paysim_by_steps/part-00000-f31a50f0-d893-4565-809e-5d9cba0bef44-c000.csv\", header=True, inferSchema=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-26T05:43:20.686552Z",
     "start_time": "2025-04-26T05:43:20.419143Z"
    }
   },
   "id": "3866297b1e44284d",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|step|count|\n",
      "+----+-----+\n",
      "| 135|27556|\n",
      "+----+-----+\n"
     ]
    }
   ],
   "source": [
    "part.groupBy(\"step\").count().show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-26T05:43:22.707492Z",
     "start_time": "2025-04-26T05:43:22.557203Z"
    }
   },
   "id": "fb6a7f62ef8017cb",
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Wersja strumieniowa\n",
    "\n",
    "Stwórzmy strumieniową wersję tego wejścia.\n",
    "Będziemy odczytywać każdy plik pojedynczo, tak jakby był częścią strumienia."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de3d99d721601242"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dataSchema = df.schema\n",
    "dataSchema"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1157ef3a696729b",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "`maxFilesPerTrigger` pozwala kontrolować, jak szybko Spark będzie odczytywał wszystkie pliki w folderze.\n",
    "W tym przykładzie ograniczamy przepływ strumienia do jednego pliku na każde wyzwolenie (trigger)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea87cf4204c0c7d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "streaming = spark.readStream.schema(dataSchema).option(\"header\", \"true\").option( \"maxFilesPerTrigger\", 1).csv(f\"{output_tables}/paysim_by_steps\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf9088b9a087e000",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Skonfigurujmy transformację.\n",
    "\n",
    "Kolumna `nameDest` to identyfikator odbiorcy transakcji:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "136c7506a469f959"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dest_count = streaming.groupBy(\"nameDest\").count().orderBy(F.desc(\"count\"))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9d3ec4a08c0fff5",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Teraz, gdy mamy naszą transformację, musimy określić miejsce docelowe wyników (sink).\n",
    "\n",
    "W tym przykładzie zapiszemy wyniki do pamięci (memory sink), aby przechowywać je w pamięci RAM.\n",
    "\n",
    "Musimy także określić, w jaki sposób Spark będzie wypisywać te dane.\n",
    "\n",
    "W tym przykładzie użyjemy trybu complete output mode (przepisywanie wszystkich kluczy wraz z ich licznikami po każdym wyzwoleniu – triggerze).\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ab40e140da2ca47"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dest_count.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c545ab1f4ec00e2d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "activityQuery = (\n",
    "    dest_count.writeStream.queryName(\"dest_counts\")\n",
    "    .format(\"memory\")\n",
    "    .outputMode(\"complete\")\n",
    "    .start()\n",
    ")\n",
    "\n",
    "# nie potrzebujemy w notebooku\n",
    "# activityQuery.awaitTermination(1)                   \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa6dc82172c21df8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "count_threshold = 2\n",
    "\n",
    "for x in range(5):\n",
    "    _df = spark.sql(f\"SELECT * FROM dest_counts WHERE nameDest != 'nameDest' AND count >= {count_threshold}\")\n",
    "    if _df.count() > 0:\n",
    "        print(\"####### x:\", x)\n",
    "        _df.show(10)\n",
    "    time.sleep(0.5)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be9db7ae06c3aaeb",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sprawdźmy czy strumień jest aktywny:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "16c038b0464f0dbb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "spark.streams.active[0].isActive"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e9670c0eb4a8483",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "activityQuery.status"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b2cd01c8c988a5c",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Na koniec możemy wyłączyć stream:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "849974a53324f2e5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "activityQuery.stop()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36bcae4879a9f2fa",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "spark.stop()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc074ada6a097d16",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "cefe51481bb2e7e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
