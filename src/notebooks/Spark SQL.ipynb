{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Wprowadzenie do Spark SQL"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ca4a5c9cde60c23"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DataFrame w Spark SQL\n",
    "\n",
    "DataFrame to abstrakcyjna struktura danych w Spark SQL, która reprezentuje tabelę danych z kolumnami i wierszami.\n",
    "DataFrame jest rozszerzeniem RDD, które jest zbiorem obiektów RDD, w którym każdy obiekt jest strukturą danych zawierającą nazwane kolumny (schemat danych).\n",
    "\n",
    "DataFrame można tworzyć na różne sposoby:\n",
    "- z obiektu RDD\n",
    "- z pliku CSV, JSON, Parquet\n",
    "- z bazy danych\n",
    "- z innych źródeł danych\n",
    "- z innych DataFrame\n",
    "- z kolekcji danych\n",
    "- z danych strumieniowych\n",
    "- z danych zewnętrznych\n",
    "- z danych z API\n",
    " "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1d58e31074f7b3c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inicjowanie Sparka\n",
    "Pracę ze Sparkiem zaczynamy od zainicjowania sesji Sparka.\n",
    "Aby zainicjować Sparka, musimy zaimportować pakiet `findspark` i uruchomić metodę `init()`:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "54ce891f88cfdc49"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fef2ac-64f8-422d-b03f-4945e41ade4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init() "
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Następnie tworzymy obiekt sesji Sparka. Zwróć uwagę na ustawienie nazwy aplikacji Sparka: "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ea7c53d57759749"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d34f07-0c73-4234-b8a8-d6743b714287",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1549728-87b5-49b2-ba24-b5ac7dbda801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obiekt sesji zwykle ma nazwę \"spark\"\n",
    "spark = SparkSession.builder.appName(\"DataScience\").getOrCreate() \n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tworzenie obiektów DataFrame\n",
    "\n",
    "W pierwszym ćwiczeniu spróbujemy stworzyć obiekty DataFrame z kolekcji danych, obiektu RDD, pliku CSV oraz pliku Parquet.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "85cff230dad0173d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Utworzenie obiektu DataFrame z obiektu RDD"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e0248d5e7f589f1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rdd = spark.sparkContext.parallelize([1, 2, 3, 4, 5])\n",
    "# musimy zmienić obiekt RDD na obiekt RDD zawierający krotki, ponieważ obiekt RDD musi zawierać strukturę danych\n",
    "# nie może zawierać pojedynczych wartości\n",
    "rdd = rdd.map(lambda x: (x, ))\n",
    "rdd.collect()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a32dc8e575541466",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Mając obiekt RDD, możemy zmienić go na obiekt DataFrame za pomocą metody `.toDF()`."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a3e1fa31292d89b8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = rdd.toDF()\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "34c4ec77ed66284",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# funkcja show() wyświetla zawartość obiektu DataFrame\n",
    "df.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36a7729f060b2494",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# funkcja printSchema() wyświetla schemat danych obiektu DataFrame\n",
    "df.printSchema()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "13234aec641d112e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# funkcja describe() wyświetla statystyki opisowe obiektu DataFrame\n",
    "df.describe().show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7139f2d9b21252e1",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Jak widać powyżej, obiekt DataFrame zawiera kolumnę z nazwą `_1`. Musimy zmienić nazwę kolumny na bardziej opisową."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9fb5ab73047118cc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = rdd.toDF([\"value\"])\n",
    "df.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d697d8708d334bc6",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Typ danych w obiekcie DataFrame jest automatycznie ustawiany na podstawie danych wejściowych. Możemy sprawdzić typ danych za pomocą metody `dtypes`."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31e23da125b9afb0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.dtypes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8bd2ba9741b20a89",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Jak widać powyżej, typ danych w kolumnie `value` został ustawiony na `int`. Możemy zobaczyć schemat danych za pomocą metody `schema`."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e90cdac195f6d69"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.schema"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be0618a210991405",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.schema.names\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d597057583205a5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.schema.fields"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "960e0d5774bd0cf7",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Utworzenie obiektu DataFrame z kolekcji danych\n",
    "\n",
    "Użyjemy metody `createDataFrame()` do utworzenia obiektu DataFrame z kolekcji danych.\n",
    "Wartości w kolumnach obiektu DataFrame mogą być różnych typów danych."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "83710a1d94272f3f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data = [(\"John\", 25), (\"Anna\", 23), (\"Mike\", 30), (\"Jane\", 22)]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a3822e206b8eafde",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data, [\"name\", \"age\"])\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a3fe5ca5c8600107",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "716fd5e815efa35",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Utworzenie obiektu DataFrame z pliku CSV\n",
    "\n",
    "DataFrame można również utworzyć z pliku CSV. W tym celu używamy metody `read.csv()`.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3fb9eb8f19909332"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"../../data/stock/stock.csv\", header=True, inferSchema=True)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c280fec2e6ac1a8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.show(5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "65935bc17580b623",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Utworzenie obiektu DataFrame z pliku Parquet\n",
    "\n",
    "Parquet to format pliku binarnego używany w Sparku do przechowywania danych."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ef4db9d54b571c4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"../../data/sklep/categories\")\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f379829414736dd",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Podstawowe akcje na obiektach DataFrame\n",
    "Akcja to operacja, która zwraca wartość do sterownika programu po przetworzeniu danych."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de9329468668bc7d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"../../data/sklep/categories\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "756a5ad8420149fb",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### show()\n",
    "\n",
    "`show()` wyświetla zawartość obiektu DataFrame."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a70ce061ee892c5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.show(5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1b3b20344e6bdad",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.show(5, truncate=False)  # truncate=False wyświetla całą zawartość kolumny"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dca1685daab001aa",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### printSchema()\n",
    "\n",
    "`printSchema()` wyświetla schemat danych obiektu DataFrame."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b199d72c0ada036f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.printSchema()    # wyświetla schemat danych obiektu DataFrame"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ca049336ee10637",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### describe()\n",
    "\n",
    "`describe()` wyświetla statystyki opisowe obiektu DataFrame."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1468b16fb8b61b0e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.describe().show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b0ca993a2794b64",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.describe(\"category_id\").show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c01e6d7538291a1b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.describe(\"category_id\", \"category_name\").show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bead6b42a6e7fb19",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### count()\n",
    "\n",
    "`count()` zwraca liczbę wierszy obiektu DataFrame."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ebee6d55a73d6466"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.count()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "33e877ce1056051f",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### select()\n",
    "\n",
    "`select()` zwraca nowy obiekt DataFrame z wybranymi kolumnami."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "244fd918f4ebba5b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.select(\"*\").show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28aa025452f09e10",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.select(\"category_id\", \"category_name\").show(5)       # wybiera kolumny category_id i category"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f24e028f71a842",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.select(df[\"category_id\"], df[\"category_name\"]).show(5)       # można odwoływać się do kolumn za pomocą nawiasów kwadratowych"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2fc9b16b3e816bd6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.select(df.category_id, df.category_name).show(5)     # można odwoływać się do kolumn za pomocą kropki"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db497c3f92990951",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### filter()\n",
    "\n",
    "`filter()` zwraca nowy obiekt DataFrame z wierszami spełniającymi warunek.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10ab2ef3a4064722"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df2 = df.filter(df[\"category_id\"] == 1)\n",
    "df2.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa1b620ba141dc2d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.filter(df[\"category_id\"] == 1).select(\"category_id\", \"category_name\").show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a50bb3db6ffd0ff",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.filter(df[\"category_id\"] == 1).filter(df[\"category_name\"] == \"Football\").show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fee1001df4f90c42",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### distinct()\n",
    "\n",
    "`distinct()` zwraca obiekt DataFrame bez duplikatów.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7984e74e16924080"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.select(\"category_department_id\").distinct().show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "230942e94ffb166f",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### orderBy()\n",
    "\n",
    "`orderBy()` sortuje wiersze obiektu DataFrame według kolumny."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a8f2dfd2834ac3cb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.orderBy(\"category_id\").show(5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed570b398954cec7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.orderBy(df[\"category_id\"].desc()).show(5)        # sortowanie malejące według kolumny category_id"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf2111048ba6dc0b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.orderBy(df[\"category_id\"].asc(), df[\"category_name\"].desc()).show(5)  # sortowanie rosnące według kolumny category_id oraz malejące według kolumny category_name"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1db4053ae8c43c3d",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### groupBy()\n",
    "\n",
    "`groupBy()` grupuje wiersze obiektu DataFrame według kolumny."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0876b12ce721628"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.groupBy(\"category_id\").count().show(5)    # grupuje wiersze według kolumny category_id i zlicza liczbę wierszy w każdej grupie"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c4d016a83dd9a7a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.groupBy(\"category_id\").count().show(5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d905e7e4fd4881f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.groupBy(\"category_id\").agg({\"category_name\": \"count\"}).show(5)    # grupuje wiersze według kolumny category_id i zlicza liczbę wierszy w każdej grupie"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "53022d2b960d307f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.groupBy(\"category_id\").agg({\"category_name\": \"count\", \"category_id\": \"sum\"}).show(5)    # grupuje wiersze według kolumny category_id i zlicza liczbę wierszy w każdej grupie"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf8ac427a0491020",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.groupBy(\"category_id\").agg({\"category_name\": \"count\", \"category_id\": \"sum\"}).orderBy(\"category_id\").show(5)    # grupuje wiersze według kolumny category_id i zlicza liczbę wierszy w każdej grupie"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "98cb377358f618d7",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### join()\n",
    "\n",
    "`join()` łączy dwa obiekty DataFrame na podstawie kolumny.\n",
    "\n",
    "Wykorzystamy dwa obiekty DataFrame: `categories` oraz `products`.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3855398afce87a7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "categories = spark.read.parquet(\"../../data/sklep/categories\")\n",
    "products = spark.read.parquet(\"../../data/sklep/products\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0d26202c10eb730",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "categories.show(5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bafcfd812597ac0e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "products.show(5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a920d3e4c763124",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "categories.join(products, categories[\"category_id\"] == products[\"product_category_id\"]).show(5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac14603aa3e9ee3d",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Wyróżniamy kilka typów łączenia obiektów DataFrame:\n",
    "\n",
    "- inner join - zwraca wiersze, które mają pasujące wartości w obu obiektach DataFrame\n",
    "- outer join - zwraca wiersze, które mają pasujące wartości w jednym z obiektów DataFrame\n",
    "- left join - zwraca wiersze, które mają pasujące wartości w lewym obiekcie DataFrame\n",
    "- right join - zwraca wiersze, które mają pasujące wartości w prawym obiekcie DataFrame\n",
    "- left semi join - zwraca wiersze z lewego obiektu DataFrame, które mają pasujące wartości w prawym obiekcie DataFrame\n",
    "- left anti join - zwraca wiersze z lewego obiektu DataFrame, które nie mają pasujących wartości w prawym obiekcie DataFrame\n",
    "- cross join - zwraca iloczyn kartezjański obu obiektów DataFrame\n",
    "- natural join - zwraca wiersze, które mają pasujące wartości w obu obiektach DataFrame, ale bez powtarzających się kolumn\n",
    "\n",
    " \n",
    "join_types = [\"inner\", \"cross\", \"outer\", \"full\", \"left_outer\", \"right_outer\"]\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96474b27c9858fa4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "categories.join(products, categories[\"category_id\"] == products[\"product_category_id\"], \"inner\").show(5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ef89fb42f60e5cae",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "categories.join(products, categories[\"category_id\"] == products[\"product_category_id\"], \"outer\").show(5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "741c1cc056971e96",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### union()\n",
    "\n",
    "`union()` łączy dwa obiekty DataFrame w jeden obiekt DataFrame.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bfce979c56226182"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df1 = spark.createDataFrame([(1, \"John\"), (2, \"Anna\")], [\"id\", \"name\"])\n",
    "df2 = spark.createDataFrame([(3, \"Mike\"), (4, \"Jane\")], [\"id\", \"name\"])\n",
    "df1.show()\n",
    "df2.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "79192565ce7ee4e8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df1.union(df2).show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a80d82067a5b76f",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### withColumn()\n",
    "\n",
    "`withColumn()` dodaje nową kolumnę do obiektu DataFrame.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e95642d26468f1d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.withColumn(\"new_column\", df[\"category_id\"] + 1).show(5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "90c3d22cc0b2afeb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.withColumn(\"new_column\", df[\"category_id\"] + 1).select(\"category_id\", \"new_column\").show(5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "835c4bfa19bb10e",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### drop()\n",
    "\n",
    "`drop()` usuwa kolumnę z obiektu DataFrame."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fcf077627ba98e34"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.drop(\"category_id\").show(5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e78fdca7dedf45d0",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### na()\n",
    "\n",
    "`na()` zwraca obiekt DataFrame z wartościami brakującymi zastąpionymi wartościami.\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc0d35b647434d51"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# przykładowy obiekt DataFrame z wartościami brakującymi\n",
    "df = spark.createDataFrame([(1, \"John\"), (2, None), (3, \"Mike\"), (4, \"Jane\")], [\"id\", \"name\"])\n",
    "df.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b4acfb94bd3a90a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.na.fill(\"Anna\").show()   # zastępuje wartości brakujące wartością \"Anna\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "43c579ad1b4e7786",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.na.fill({\"name\": \"Anna\"}).show()   # zastępuje wartości brakujące wartością \"Anna\" w kolumnie name"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b46065ebfc9391f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.na.drop().show()   # usuwa wiersze z wartościami brakującymi"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d931c42088d6730",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### replace()\n",
    "\n",
    "`replace()` zastępuje wartości w obiekcie DataFrame.\n",
    "Zamiana wartości w obiekcie DataFrame jest możliwa tylko dla kolumn typu string.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8fe5f423843aebe2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.replace(\"John\", \"Anna\").show(5)   # zastępuje wartość \"John\" wartością \"Anna\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4fc57f18e002dce1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "474d0ff74462fcc6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### cache()\n",
    "\n",
    "`cache()` zapisuje obiekt DataFrame w pamięci podręcznej."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d05b221a6658b9c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([(1, \"John\"), (2, \"Anna\"), (3, \"Mike\"), (4, \"Jane\")], [\"id\", \"name\"])\n",
    "df.cache()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d03e685a548bf22c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5fa76f3e169136",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### unpersist()\n",
    "\n",
    "`unpersist()` usuwa obiekt DataFrame z pamięci podręcznej. Pozwala to na zwolnienie pamięci podręcznej."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3eea32bcbc06050c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.unpersist()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "20a0e41e9e0cd992",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.show(5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "38e3c678eef20cd6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.take(5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9de2d5c88587ab8c",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### collect(), take(), head(), first(), show(), toPandas()\n",
    "\n",
    "`collect()` zwraca wszystkie wiersze obiektu DataFrame do sterownika programu.\n",
    "`take(n)` zwraca n pierwszych wierszy obiektu DataFrame do sterownika programu.\n",
    "`head(n)` zwraca n pierwszych wierszy obiektu DataFrame do sterownika programu.\n",
    "`first()` zwraca pierwszy wiersz obiektu DataFrame do sterownika programu.\n",
    "`show(n)` wyświetla n pierwszych wierszy obiektu DataFrame.\n",
    "`toPandas()` zwraca obiekt DataFrame jako obiekt Pandas.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb6084d7afa8b68b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### write()\n",
    "\n",
    "`write()` zapisuje obiekt DataFrame do pliku."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1324881800e4dc6e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"../../data/sklep/categories\")\n",
    "df.write.csv(\"categories.csv\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "71d4d02a73d09648",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Zapytania SQL na obiektach DataFrame\n",
    "\n",
    "Obiekty DataFrame można przekształcić na tabele tymczasowe, które można wykorzystać w zapytaniach SQL."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c630ff757503404d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"../../data/sklep/categories\")\n",
    "df.createOrReplaceTempView(\"categories\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b73984e70f76d081",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT * FROM categories\").show(5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d5c6ad1564079be1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a98e7b01d8cbfa08"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
