{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Wprowadzenie do Spark RDD"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ca4a5c9cde60c23"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RDD = Resilient Distributed Datasets\n",
    "Rozproszone obiekty RDD są reprezentacją rozproszonego zbioru danych.\n",
    "\n",
    "Na obiektach RDD dozwolone są dwa typy operacji:\n",
    "\n",
    "1. Transformacje: operacje, które tworzą nowe zbiory danych z istniejących RDD. \n",
    "\n",
    "Przykłady to `map`, `filter`, `flatMap`, `groupByKey`, `reduceByKey`, `sample`, `union`, `intersection`, `distinct`, `coalesce`, `repartition`.\n",
    "\n",
    "\n",
    "2. Akcje: operacje, które zwracają wartość do sterownika programu po przetworzeniu danych.\n",
    "\n",
    "Przykłady to `reduce`, `collect`, `count`, `first`, `take`, `takeSample`, `takeOrdered`, `saveAsTextFile`, `countByKey`, `foreach`.\n",
    "\n",
    "W tym zeszycie skupimy się na podstawowych transformacjach i akcjach na obiektach RDD.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1d58e31074f7b3c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inicjowanie Sparka\n",
    "Pracę ze Sparkiem zaczynamy od zainicjowania sesji Sparka.\n",
    "Aby zainicjować Sparka, musimy zaimportować pakiet `findspark` i uruchomić metodę `init()`:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "54ce891f88cfdc49"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fef2ac-64f8-422d-b03f-4945e41ade4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init() "
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Następnie tworzymy obiekt sesji Sparka. Zwróć uwagę na ustawienie nazwy aplikacji Sparka: "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ea7c53d57759749"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d34f07-0c73-4234-b8a8-d6743b714287",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1549728-87b5-49b2-ba24-b5ac7dbda801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obiekt sesji zwykle ma nazwę \"spark\"\n",
    "spark = SparkSession.builder.appName(\"DataScience\").getOrCreate() \n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Mając obiekt sesji możemy wyciągnąć z niego tzw. kontekst Sparka, który pozwala na bezpośrednią pracę z kolekcjami obiektów RDD oraz podstawowymi usługami Sparka."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9663021b13aef788"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1081eb5b-b3d6-4e2d-81a8-83b06b059f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext\n",
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tworzenie obiektów RDD\n",
    "\n",
    "W pierwszym ćwiczeniu spróbujemy stworzyć obiekty RDD z różnych kolekcji danych.\n",
    "\n",
    "W tym celu wykonamy następujące kroki:\n",
    "- utworzymy obiekt RDD z listy liczb\n",
    "- utworzymy obiekt RDD z pliku tekstowego"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "85cff230dad0173d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Utworzenie obiektu RDD z listy liczb"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e0248d5e7f589f1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([1, 2, 3, 4, 5])       # parallelize() jest tranformacją, która tworzy obiekt RDD z listy\n",
    "rdd"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a32dc8e575541466",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rdd.collect()   # collect() jest akcją, która zwraca wartość obiektu RDD do sterownika programu"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9321a3e299209fe6",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Transformacja `parallelize` przyjmuje nie tylko proste listy, ale również bardziej złożone struktury danych, takie jak listy zagnieżdżone, słowniki, itp."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a25b21ea93991419"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([1, 2, [3, 4], 5, {\"a\": 1, \"b\": 2}])\n",
    "rdd.collect()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2da4c2a409956c7a",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Może przyjmować również inne kolekcje danych, np. generator:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2492acfa5d05350e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rdd = sc.parallelize(range(10))\n",
    "rdd.collect()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c085501a6912c982",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Utworzenie obiektu RDD z plików\n",
    "\n",
    "RDD może czytać dane z plików w formatach binarnych oraz tekstowych. Każdy odczyt jest transformacją."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "acf93e8e1f9b32d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Poniżej użyliśmy textFile() do odczytania tekstu książki:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "82b8c9d089c15f19"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "book_rdd = sc.textFile(\"../../data/books/ulysses.txt\") # textFile() jest tranformacją tworzącą obiekt RDD z pliku tekstowego\n",
    "book_rdd"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c01dabe3c347462",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "RDD nie posiada wbudowanych funkcji do czytania plików CSV czy JSON. Obróbkę można zrobić samemu lub skorzystać z zewnętrznych bibliotek. W praktyce korzysta się z modułu DataFrame. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c0cd55a9cd51296"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "stock_rdd = sc.textFile(\"../../data/stock/stock.csv\")  # przeczyta plik CSV jak zwykły plik tekstowy\n",
    "stock_rdd"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "241f8198af853cc8",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Podstawowe akcje na obiektach RDD\n",
    "Akcja to operacja, która zwraca wartość do sterownika programu po przetworzeniu danych."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de9329468668bc7d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rdd.collect()   # collect() jest akcją, która zwraca całą zawartość kolekcji RDD"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "756a5ad8420149fb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rdd.count()     # count() jest akcją, która zwraca ilość elementów obiektu RDD"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1b3b20344e6bdad",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rdd.first()   # first() jest akcją zwracającą pierwszy element obiektu RDD"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dca1685daab001aa",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rdd.take(5)     # take() jest akcją, która zwraca pierwsze N elementów obiektu RDD"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ee1fbebc8fc30a3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rdd.takeOrdered(5)      # takeOrdered() jest akcją, która zwraca N najmniejszych elementów obiektu RDD"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5cf674bf8f1e076d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rdd.top(5)      # top() jest akcją, która zwraca N największych elementów obiektu RDD"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc42cc71a3216676",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# to samo co takeOrdered(5) można uzyskać za pomocą dodatkowego argumentu w metodzie top()\n",
    "rdd.top(5, key=lambda x: -x)      # top() jest akcją, która zwraca N najmniejszych elementów obiektu RDD"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a16e31082998cd78",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rdd.takeSample(False, 5)                    # zwraca 5 losowych elementów obiektu RDD"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2962b8d3ca414ec4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "result = rdd.collect()  # collect() jest akcją, która zwraca wartość obiektu RDD do sterownika programu\n",
    "result[:5]             # wyświetlenie pierwszych 5 elementów obiektu RDD - za pomocą wbudowanej operacji języka Python"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c4a0563091c9db7",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Akcje agregujące\n",
    "\n",
    "Akcje agregujące to operacje, które łączą elementy obiektu RDD za pomocą funkcji.\n",
    "Przykłady to `reduce`, `fold`, `aggregate`, `countByKey`, `countByValue`, `sum`, `mean`, `max`, `min`, `stdev`, `variance`."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f89a309c6510e7c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([1, 2, 3, 4, 5])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fdb330ad9d32081",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### reduce()\n",
    "reduce() ma za zadanie zredukować elementy obiektu RDD do jednego elementu za pomocą funkcji.\n",
    "\n",
    "Przykładem może być suma lub maksimum elementów w RDD. Kluczową rzeczą jest to, że funkcja przekazywana do reduce musi być przemienna (wynik operacji nie zależy od kolejności argumentów) oraz łączna (wynik jest taki sam niezależnie od grupowania operacji).\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "690c7f244d103b7f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rdd.reduce(lambda x, y: x + y)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2f13be6bc09539e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rdd.reduce(lambda x, y: x * y)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "38cd490c67bda909",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### fold()\n",
    "\n",
    "fold() działa podobnie do reduce(), ale wymaga wartości początkowej.\n",
    "\n",
    " Wartość początkowa jest używana jako początkowy wynik oraz jako argument dla operacji w przypadku pustych partycji RDD. To sprawia, że fold jest bardziej ogólna niż reduce. \n",
    " Wartość początkowa oraz funkcja użyta w fold również muszą być przemienne i łączne, aby zagwarantować poprawność wyniku w rozproszonym środowisku obliczeniowym.\n",
    " "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b2ac8983549ab3b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rdd.fold(0, lambda x, y: x + y)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d547f087e777b799",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rdd.fold(1, lambda x, y: x * y)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "68a65e10e30a5a67",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### aggregate()\n",
    "\n",
    "aggregate() jest bardziej ogólna niż reduce() i fold(). Pozwala na zdefiniowanie dwóch funkcji: funkcji agregującej oraz funkcji łączącej.\n",
    "\n",
    "Funkcja agregująca jest wywoływana na każdej partycji obiektu RDD i zwraca wartość typu U. Funkcja łącząca łączy wyniki funkcji agregującej z różnych partycji.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "488f2cd40452c635"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rdd.aggregate((0, 0), \n",
    "              (lambda acc, value: (acc[0] + value, acc[1] + 1)), \n",
    "              (lambda acc1, acc2: (acc1[0] + acc2[0], acc1[1] + acc2[1])))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51dc4cbc876fb6f7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rdd.aggregate((1, 1), \n",
    "              (lambda acc, value: (acc[0] * value, acc[1] + 1)), \n",
    "              (lambda acc1, acc2: (acc1[0] * acc2[0], acc1[1] + acc2[1]))\n",
    "             )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3041008715eae8e2",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### countByKey()\n",
    "\n",
    "countByKey() zlicza liczbę wystąpień każdego klucza w obiekcie RDD, który jest zbiorem par klucz-wartość.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a467b9d2e03ff5bc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([(\"a\", 1), (\"b\", 2), (\"a\", 3), (\"b\", 4), (\"c\", 5)])\n",
    "rdd.countByKey()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3897109c6d2f75fa",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### countByValue()\n",
    "\n",
    "countByValue() zlicza liczbę wystąpień każdej wartości w obiekcie RDD."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb6463930ca68e7f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([1, 2, 3, 4, 5, 1, 2, 3, 4, 5])\n",
    "rdd.countByValue()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "72f0f222995b3c54",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### sum()\n",
    "\n",
    "sum() zwraca sumę elementów obiektu RDD.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "173c34ca736a74f8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([1, 2, 3, 4, 5])\n",
    "rdd.sum()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d878b3f54e8be4ba",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### mean(), max(), min(), stdev(), variance()\n",
    "\n",
    "mean(), max(), min(), stdev(), variance() zwracają odpowiednio średnią, maksimum, minimum, odchylenie standardowe oraz wariancję elementów obiektu RDD."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "390f13a49337db42"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rdd.mean()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5fa5396574ba3a02",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rdd.max()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8caea36e8751fe18",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rdd.min()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d93e33a916a7755",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Transformacje na obiektach RDD\n",
    "\n",
    "Transformacje to operacje, które tworzą nowe zbiory danych z istniejących RDD."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f71046160dc2eabc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### map()\n",
    "\n",
    "map() jest najbardziej podstawową transformacją. Przyjmuje funkcję, która jest stosowana do każdego elementu obiektu RDD i zwraca nowy obiekt RDD.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1061adf3252aa5a6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([1, 2, 3, 4, 5])\n",
    "rdd.map(lambda x: x * 2).collect()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3764f4821826567d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rdd.map(lambda x: x ** 2).collect()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd1122b72c3aea5c",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### flatMap()\n",
    "\n",
    "flatMap() działa podobnie do map(), ale zwraca listę wyników dla każdego elementu obiektu RDD.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b49a9064734eb920"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([1, 2, 3, 4, 5])\n",
    "rdd.flatMap(lambda x: [x, x * 2]).collect()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6bd03feb6786619a",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### filter()\n",
    "\n",
    "filter() zwraca nowy obiekt RDD, który zawiera tylko elementy spełniające warunek podany w funkcji.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e4ac105d1dbf64fa"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([1, 2, 3, 4, 5])\n",
    "rdd.filter(lambda x: x % 2 == 0).collect()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "30c410ad48ca7336",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### groupByKey()\n",
    "\n",
    "groupByKey() grupuje elementy obiektu RDD według klucza."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b7637af68cbb6b06"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([(\"a\", 1), (\"b\", 2), (\"a\", 3), (\"b\", 4), (\"c\", 5)])\n",
    "result = rdd.groupByKey().collect()\n",
    "for key, value in result:\n",
    "    print(key, list(value))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac17970019c7ad93",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rdd.groupByKey().mapValues(list).collect()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "727b72e6470b250a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rdd.groupByKey().mapValues(lambda x: sum(x)).collect()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c301a10ed24ebdab",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rdd.groupByKey().mapValues(lambda x: sum(x) / len(x)).collect()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "87f928c7f30206c",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### reduceByKey()\n",
    "\n",
    "reduceByKey() działa podobnie do groupByKey(), ale zamiast grupować elementy, redukuje je za pomocą funkcji przekazanej jako argument.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe9545efd5956984"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([(\"a\", 1), (\"b\", 2), (\"a\", 3), (\"b\", 4), (\"c\", 5)])\n",
    "rdd.reduceByKey(lambda x, y: x + y).collect()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f4b74d54a71dedb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rdd.reduceByKey(lambda x, y: x * y).collect()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c584c70836eb02",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### sortByKey()\n",
    "\n",
    "sortByKey() sortuje elementy obiektu RDD według klucza.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f6186faa587dd6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([(\"b\", 2), (\"a\", 1), (\"c\", 3)])\n",
    "rdd.sortByKey().collect()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc27945b52f52cf7",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### join()\n",
    "\n",
    "join() łączy dwa obiekty RDD na podstawie klucza.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "53b63ca8913b4f05"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rdd1 = sc.parallelize([(\"a\", 1), (\"b\", 2), (\"c\", 3)])\n",
    "rdd2 = sc.parallelize([(\"a\", 4), (\"b\", 5), (\"c\", 6)])\n",
    "rdd1.join(rdd2).collect()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1fcab16830fc053",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### union()\n",
    "\n",
    "union() łączy dwa obiekty RDD w jeden obiekt RDD."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e85db6777bb8d5e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rdd1 = sc.parallelize([1, 2, 3])\n",
    "rdd2 = sc.parallelize([4, 5, 6])\n",
    "rdd1.union(rdd2).collect()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f40b227d1f3ad182",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### intersection()\n",
    "\n",
    "intersection() zwraca obiekt RDD, który zawiera elementy wspólne dwóch obiektów RDD."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b1e55aa27884de3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rdd1 = sc.parallelize([1, 2, 3, 4, 5])\n",
    "rdd2 = sc.parallelize([4, 5, 6, 7, 8])\n",
    "rdd1.intersection(rdd2).collect()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b9328d76e1d1429",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### distinct()\n",
    "\n",
    "distinct() zwraca obiekt RDD bez duplikatów.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8810023da4020331"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([1, 2, 3, 4, 5, 1, 2, 3, 4, 5])\n",
    "rdd.distinct().collect()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0f526626f025ea3",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Partycje\n",
    "\n",
    "Partycje to podstawowa jednostka obliczeniowa w Sparku. Każda partycja to fragment danych, który jest przetwarzany przez pojedynczy wątek.\n",
    "Transformacje na obiektach RDD są wykonywane na partycjach, a nie na pojedynczych elementach."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "26e92d20896e87e4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rdd.getNumPartitions()   # zwraca ilość partycji obiektu RDD"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b59651d2644e9a7c",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Domyślnie, Spark tworzy tyle partycji, ile jest rdzeni w klastrze. Możemy zmienić liczbę partycji za pomocą metody `repartition()` lub `coalesce()`.\n",
    "Różnica między nimi polega na tym, że `repartition()` zawsze tworzy nowe partycje, podczas gdy `coalesce()` może łączyć istniejące partycje."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f54f65dbec281319"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rdd = rdd.repartition(4)   # repartition() jest transformacją, która zmienia liczbę partycji obiektu RDD\n",
    "rdd.getNumPartitions()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "799445e685aaf49c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rdd = rdd.coalesce(2)     # coalesce() jest transformacją, która zmienia liczbę partycji obiektu RDD\n",
    "rdd.getNumPartitions()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f618b49f11de5fb2",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Zapisywanie obiektów RDD\n",
    "\n",
    "Obiekty RDD można zapisać do plików w formatach tekstowym oraz binarnym.\n",
    "Tworzony jest katalog, w którym zapisywane są pliki z danymi.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "925e00db3ffbd9b7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([1, 2, 3, 4, 5])\n",
    "rdd.saveAsTextFile(\"output\")   # zapisuje obiekt RDD do pliku tekstowego"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "225d9077592e8725",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rdd.saveAsPickleFile(\"output2\")   # zapisuje obiekt RDD do pliku binarnego"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eaf71a3e7aa14c3d",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
